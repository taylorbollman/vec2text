{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf7NF9JluRPA"
      },
      "outputs": [],
      "source": [
        "# %pip install tiktoken\n",
        "# %pip install cohere\n",
        "# %pip install evaluate sacrebleu bert_score rouge_score datasets accelerate transformers sentence_transformers openai > /dev/null\n",
        "# %pip install openai\n",
        "# %pip install vec2text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import torch\n",
        "print(torch.version.cuda)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "import torch\n",
        "import sklearn\n",
        "import scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !echo 'OPENAI_API_KEY=\"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\"' >> .env\n",
        "\n",
        "load_dotenv()\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "# openai = client                         ## replace parts of code to change from openai to client "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!export BNB_CUDA_VERSION=\"\"\n",
        "!echo 'export BNB_CUDA_VERSION=\"\"' >> ~/.bashrc\n",
        "!echo 'export BNB_CUDA_VERSION=\"\"' >> ~/.bash_profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import vec2text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "Tj1nA001Ge60",
        "outputId": "b75d3e9e-1911-49c8-c0a6-84de9b98c4c8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "corrector = vec2text.load_corrector(\"text-embedding-ada-002\")\n",
        "\n",
        "vec2text.invert_strings(\n",
        "    [\n",
        "        \"Jack Morris is a PhD student at Cornell Tech in New York City\",\n",
        "        \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity\"\n",
        "    ],\n",
        "    corrector=corrector\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itfdiyvQQk1v"
      },
      "outputs": [],
      "source": [
        "vec2text.invert_strings(\n",
        "    [\n",
        "        \"Jack Morris is a PhD student at Cornell Tech in New York City\",\n",
        "        \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity\"\n",
        "    ],\n",
        "    corrector=corrector,\n",
        "    num_steps=20,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq6eVgL7GrFB"
      },
      "outputs": [],
      "source": [
        "vec2text.invert_strings(\n",
        "    [\n",
        "        \"Jack Morris is a PhD student at Cornell Tech in New York City\",\n",
        "        \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity\"\n",
        "    ],\n",
        "    corrector=corrector,\n",
        "    num_steps=20,\n",
        "    sequence_beam_width=4,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKkxKrXELjiJ",
        "outputId": "b64dfade-0ddf-46ce-ec51-b3ebc04a92af"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "\n",
        "\n",
        "def get_embeddings_openai(text_list, model=\"text-embedding-ada-002\") -> torch.Tensor:\n",
        "    batches = math.ceil(len(text_list) / 128)\n",
        "    outputs = []\n",
        "    for batch in range(batches):\n",
        "        text_list_batch = text_list[batch * 128 : (batch + 1) * 128]\n",
        "        response = openai.Embedding.create(\n",
        "            input=text_list_batch,\n",
        "            model=model,\n",
        "            encoding_format=\"float\",  # override default base64 encoding...\n",
        "        )\n",
        "        outputs.extend([e[\"embedding\"] for e in response[\"data\"]])\n",
        "    return torch.tensor(outputs)\n",
        "\n",
        "\n",
        "embeddings = get_embeddings_openai([\n",
        "      \"Jack Morris is a PhD student at Cornell Tech in New York City\",\n",
        "      \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity\"\n",
        "])\n",
        "\n",
        "\n",
        "vec2text.invert_embeddings(\n",
        "    embeddings=embeddings.cuda(),\n",
        "    corrector=corrector\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWzzoiLeI_Fw",
        "outputId": "7e35a1c3-004c-4491-f2f6-0496fb626d18"
      },
      "outputs": [],
      "source": [
        "vec2text.invert_embeddings(\n",
        "    embeddings=embeddings.mean(dim=0, keepdim=True).cuda(),\n",
        "    corrector=corrector\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dg_MkQgJB7q",
        "outputId": "21b87255-f8a4-4d1b-8b0a-836678fe0167"
      },
      "outputs": [],
      "source": [
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST9WqrK3OK5P",
        "outputId": "8328e07d-2c77-4f2e-d9e2-16067478046e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "for alpha in np.arange(0.0, 1.1, 0.1):\n",
        "  mixed_embedding = torch.lerp(input=embeddings[0], end=embeddings[1], weight=alpha)\n",
        "  text = vec2text.invert_embeddings(\n",
        "      embeddings=mixed_embedding[None].cuda(),\n",
        "      corrector=corrector,\n",
        "      # num_steps=20,\n",
        "      # sequence_beam_width=4,\n",
        "  )[0]\n",
        "  print(f'alpha={alpha:.1f}\\t', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox9gK3wwJDvM",
        "outputId": "dafa0a10-10e4-4072-cf85-b3051ad61bd8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "for alpha in np.arange(0.0, 1.0, 0.1):\n",
        "  mixed_embedding = torch.lerp(input=embeddings[0], end=embeddings[1], weight=alpha)\n",
        "  text = vec2text.invert_embeddings(\n",
        "      embeddings=mixed_embedding[None].cuda(),\n",
        "      corrector=corrector,\n",
        "      num_steps=20,\n",
        "      sequence_beam_width=4,\n",
        "  )[0]\n",
        "  print(f'alpha={alpha:.1f}\\t', text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
